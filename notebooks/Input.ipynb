{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eca7d69-3f17-4306-84d0-58a0363144fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gerar embeddings por chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Melvin\\anaconda3\\envs\\projeto_proteina2\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Melvin\\anaconda3\\envs\\projeto_proteina2\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t33_650M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fazer predições base...\n",
      "\n",
      " GO terms com prob ≥ 0.5:\n",
      "('GO:0003674', 'GO:0003824', 'GO:0005488', 'GO:0016491', 'GO:0036094', 'GO:0043167')\n",
      "\n",
      " Top 10 GO terms mais prováveis:\n",
      "GO:0003674 : 0.9975\n",
      "GO:0003824 : 0.9156\n",
      "GO:0036094 : 0.6652\n",
      "GO:0043167 : 0.6336\n",
      "GO:0016491 : 0.6327\n",
      "GO:0005488 : 0.5595\n",
      "GO:0043169 : 0.4801\n",
      "GO:0140096 : 0.4790\n",
      "GO:0051213 : 0.4551\n",
      "GO:0046872 : 0.4098\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "# --- Parâmetros ---\n",
    "SEQ_FASTA = \"MPISSSSSSSTKSMRRAASELERSDSVTSPRFIGRRQSLIEDARKEREAAAAAAEAAEATEQIVFEEEDGKALLNLFFTLRSSKTPALSRSLKVFETFEAKIHHLETRPCRKPRDSLEGLEYFVRCEVHLSDVSTLISSIKRIAEDVKTTKEVKFHWFPKKISELDRCHHLITKFDPDLDQEHPGFTDPVYRQRRKMIGDIAFRYKQGEPIPRVEYTEEEIGTWREVYSTLRDLYTTHACSEHLEAFNLLERHCGYSPENIPQLEDVSRFLRERTGFQLRPVAGLLSARDFLASLAFRVFQCTQYIRHASSPMHSPEPDCVHELLGHVPILADRVFAQFSQNIGLASLGASEEDIEKLSTLYWFTVEFGLCKQGGIVKAYGAGLLSSYGELVHALSDEPERREFDPEAAAIQPYQDQNYQSVYFVSESFTDAKEKLRSYVAGIKRPFSVRFDPYTYSIEVLDNPLKIRGGLESVKDELKMLTDALNVLA\"\n",
    "TOP_N = 10\n",
    "\n",
    "# --- 1. Função para dividir sequência (512 para Protbert e Protbertbfd. 1024 para ESM2) ---\n",
    "def slice_sequence(seq, chunk_size):\n",
    "    return [seq[i:i+chunk_size] for i in range(0, len(seq), chunk_size)]\n",
    "\n",
    "# --- 2. Função para gerar embeddings médios ---\n",
    "def get_embedding_mean(model_name, seq, chunk_size):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "    model     = AutoModel.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    chunks = [seq[i:i+chunk_size] for i in range(0, len(seq), chunk_size)]\n",
    "    embeddings = []\n",
    "\n",
    "    for chunk in chunks:\n",
    "        seq_chunk = \" \".join(list(chunk))\n",
    "        # tokenizar SEM truncar\n",
    "        inputs = tokenizer(seq_chunk,\n",
    "                           return_tensors=\"pt\",\n",
    "                           truncation=False,         # ≤ 512 ou 1024 já garantido\n",
    "                           padding=False)\n",
    "        with torch.no_grad():\n",
    "            cls = model(**inputs).last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(cls)\n",
    "\n",
    "    return np.mean(embeddings, axis=0, keepdims=True)   # (1, dim)\n",
    "\n",
    "print(\"A gerar embeddings por chunks...\")\n",
    "emb_pb  = get_embedding_mean(\"Rostlab/prot_bert\", SEQ_FASTA, 512)\n",
    "emb_bfd = get_embedding_mean(\"Rostlab/prot_bert_bfd\", SEQ_FASTA, 512)\n",
    "emb_esm = get_embedding_mean(\"facebook/esm2_t33_650M_UR50D\", SEQ_FASTA, 1024)\n",
    "\n",
    "# --- 3. Carregar os MLPs base ---\n",
    "mlp_pb  = load_model(\"models/protbert_mlp.keras\")\n",
    "mlp_bfd = load_model(\"models/protbertbfd_mlp.keras\")\n",
    "mlp_esm = load_model(\"models/esm2_mlp.keras\")\n",
    "\n",
    "# --- 4. Gerar predições base (garantir 597 colunas) ---\n",
    "print(\"A fazer predições base...\")\n",
    "y_pb  = mlp_pb.predict(emb_pb)[:, :597]\n",
    "y_bfd = mlp_bfd.predict(emb_bfd)[:, :597]\n",
    "y_esm = mlp_esm.predict(emb_esm)[:, :597]\n",
    "\n",
    "# --- 5. Concatenar para o stacking ---\n",
    "X_stack = np.concatenate([y_pb, y_bfd, y_esm], axis=1)\n",
    "\n",
    "# --- 6. Carregar modelo de stacking ---\n",
    "stacking = load_model(\"models/modelo_ensemble_stacking.keras\")\n",
    "y_pred = stacking.predict(X_stack)\n",
    "\n",
    "# --- 7. Carregar binarizador (597 GO terms) ---\n",
    "mlb = joblib.load(\"data/mlb_597.pkl\")\n",
    "go_terms = mlb.classes_\n",
    "\n",
    "# --- 8. Mostrar resultados ---\n",
    "print(\"\\n GO terms com prob ≥ 0.5:\")\n",
    "predicted_terms = mlb.inverse_transform((y_pred >= 0.5).astype(int))\n",
    "print(predicted_terms[0] if predicted_terms[0] else \"Nenhum GO term acima de 0.5\")\n",
    "\n",
    "print(f\"\\n Top {TOP_N} GO terms mais prováveis:\")\n",
    "top_idx = np.argsort(-y_pred[0])[:TOP_N]\n",
    "for i in top_idx:\n",
    "    print(f\"{go_terms[i]} : {y_pred[0][i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959e7d9-15ba-4533-a2bb-ddd7df2a639d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

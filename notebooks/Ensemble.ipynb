{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbbb46c-1a00-4585-9ecd-a490a46e8b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go.obo: fmt(1.2) rel(2025-03-16) 43,544 Terms\n",
      "mlb com 597 GO terms guardado em data/mlb_597.pkl\n",
      "     ProtBERT  Fmax=0.6616  Thr=0.40  AuPRC=0.7009  Smin=13.9047\n",
      " ProtBERT-BFD  Fmax=0.6573  Thr=0.41  AuPRC=0.6925  Smin=13.7060\n",
      "        ESM-2  Fmax=0.6375  Thr=0.39  AuPRC=0.6875  Smin=14.1194\n",
      "     Ensemble  Fmax=0.6864  Thr=0.37  AuPRC=0.7332  Smin=12.7879\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import numpy as np, joblib, math\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from goatools.obo_parser import GODag\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "GO_FILE = \"go.obo\"\n",
    "dag     = GODag(GO_FILE)\n",
    "\n",
    "# ---------- 1. y_true + GO terms (referência ProtBERT) ----------\n",
    "test_pb = joblib.load(\"embeddings/test_protbert.pkl\")\n",
    "y_true  = test_pb[\"labels\"]            # (1724, 597)  ← ground-truth\n",
    "go_ref  = list(test_pb[\"go_terms\"])    # ordem exacta das colunas\n",
    "\n",
    "n_go = len(go_ref)                     # 597\n",
    "\n",
    "# --- Recriar o MultiLabelBinarizer com os 597 termos corretos ---\n",
    "mlb = MultiLabelBinarizer(classes=go_ref)\n",
    "mlb.fit([go_ref])  # necessário para permitir inverse_transform depois\n",
    "\n",
    "# ---------- 2. Carregar predições ----------\n",
    "y_pb   = np.load(\"predictions/mf-protbert-pam1.npy\")        # 1724×597\n",
    "y_bfd  = np.load(\"predictions/mf-protbertbfd-pam1.npy\")     # 1724×597\n",
    "y_esm0 = np.load(\"predictions/mf-esm2.npy\")                 # 1724×602\n",
    "\n",
    "# ---------- 3. Remapear ESM-2 para ordem ProtBERT ----------\n",
    "mlb_esm = joblib.load(\"data/mlb.pkl\")                       # 602 GO terms\n",
    "idx_map = [list(mlb_esm.classes_).index(t) for t in go_ref]\n",
    "y_esm   = y_esm0[:, idx_map]                               # 1724×597\n",
    "\n",
    "# ---------- 4. Garantir shapes iguais ----------\n",
    "assert (y_true.shape == y_pb.shape == y_bfd.shape\n",
    "        == y_esm.shape == (1724, n_go)), \"Ainda há desalinhamento!\"\n",
    "\n",
    "# ---------- 4. Guardar mlb (y_true) alinhado ----------\n",
    "joblib.dump(mlb, \"data/mlb_597.pkl\")\n",
    "print(\"mlb com 597 GO terms guardado em data/mlb_597.pkl\")\n",
    "\n",
    "# ---------- 5. Métricas ----------\n",
    "THR = np.linspace(0,1,101)\n",
    "def fmax(y_t,y_p):\n",
    "    best,thr = 0,0\n",
    "    for t in THR:\n",
    "        y_b = (y_p>=t).astype(int)\n",
    "        tp = (y_t*y_b).sum(1); fp=((1-y_t)*y_b).sum(1); fn=(y_t*(1-y_b)).sum(1)\n",
    "        f1 = 2*tp/(2*tp+fp+fn+1e-8); m=f1.mean()\n",
    "        if m>best: best,thr = m,t\n",
    "    return best,thr\n",
    "\n",
    "def auprc(y_t,y_p):\n",
    "    p,r,_ = precision_recall_curve(y_t.ravel(), y_p.ravel()); return auc(r,p)\n",
    "\n",
    "def smin(y_t,y_p,thr,alpha=0.5):\n",
    "    y_b=(y_p>=thr).astype(int)\n",
    "    ic=-(np.log((y_t+y_b).sum(0)+1e-8)-np.log((y_t+y_b).sum()+1e-8))\n",
    "    ru=np.logical_and(y_b, np.logical_not(y_t))*ic\n",
    "    mi=np.logical_and(y_t, np.logical_not(y_b))*ic\n",
    "    return np.sqrt((alpha*ru.sum(1))**2 + ((1-alpha)*mi.sum(1))**2).mean()\n",
    "\n",
    "def show(name,y_p):\n",
    "    f,thr=fmax(y_true,y_p)\n",
    "    print(f\"{name:>13s}  Fmax={f:.4f}  Thr={thr:.2f}  \"\n",
    "          f\"AuPRC={auprc(y_true,y_p):.4f}  Smin={smin(y_true,y_p,thr):.4f}\")\n",
    "\n",
    "show(\"ProtBERT\",      y_pb)\n",
    "show(\"ProtBERT-BFD\",  y_bfd)\n",
    "show(\"ESM-2\",         y_esm)\n",
    "show(\"Ensemble\",      (y_pb + y_bfd + y_esm)/3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1807404-c2ce-48d0-b87c-a7e0fecc1728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 0s 17ms/step - loss: 0.3811 - val_loss: 0.0868\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0882 - val_loss: 0.0696\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0628 - val_loss: 0.0563\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0552 - val_loss: 0.0520\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0507 - val_loss: 0.0486\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0473 - val_loss: 0.0455\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0437 - val_loss: 0.0431\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.0414 - val_loss: 0.0414\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.0391 - val_loss: 0.0395\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0383\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0355 - val_loss: 0.0372\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0341 - val_loss: 0.0362\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0352\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0345\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0341\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0337\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0334\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0331\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0278 - val_loss: 0.0329\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0270 - val_loss: 0.0328\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0266 - val_loss: 0.0329\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0326\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0325\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0324\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0325\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0243 - val_loss: 0.0322\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0239 - val_loss: 0.0325\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.0235 - val_loss: 0.0325\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0226 - val_loss: 0.0328\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.0227 - val_loss: 0.0326\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0326\n",
      "\n",
      " STACKING (GPU-Keras MLP)\n",
      "Fmax  = 0.6937\n",
      "Thr.  = 0.34\n",
      "AuPRC = 0.7551\n",
      "Smin  = 12.2407\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- Preparar dados para stacking ---\n",
    "# (já com y_pb, y_bfd, y_esm com shape (1724, 597))\n",
    "X_stack = np.concatenate([y_pb, y_bfd, y_esm], axis=1)  # (1724, 597*3)\n",
    "y_stack = y_true.copy()                                # (1724, 597)\n",
    "\n",
    "# --- Divisão treino/validação ---\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_stack, y_stack, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- Modelo MLP (usa GPU automaticamente se disponível) ---\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation=\"relu\", input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation=\"relu\"),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_stack.shape[1], activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\")\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "          epochs=50, batch_size=64, verbose=1,\n",
    "          callbacks=[EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "# --- Prever com stacking ---\n",
    "y_pred_stack = model.predict(X_stack, batch_size=64)\n",
    "\n",
    "# --- Métricas ---\n",
    "THR = np.linspace(0, 1, 101)\n",
    "def fmax(y_t, y_p):\n",
    "    best, thr = 0, 0\n",
    "    for t in THR:\n",
    "        y_b = (y_p >= t).astype(int)\n",
    "        tp = (y_t * y_b).sum(1); fp = ((1 - y_t) * y_b).sum(1); fn = (y_t * (1 - y_b)).sum(1)\n",
    "        f1 = 2 * tp / (2 * tp + fp + fn + 1e-8); m = f1.mean()\n",
    "        if m > best: best, thr = m, t\n",
    "    return best, thr\n",
    "\n",
    "def auprc(y_t, y_p):\n",
    "    p, r, _ = precision_recall_curve(y_t.ravel(), y_p.ravel())\n",
    "    return auc(r, p)\n",
    "\n",
    "def smin(y_t, y_p, thr, alpha=0.5):\n",
    "    y_b = (y_p >= thr).astype(int)\n",
    "    ic = -(np.log((y_t + y_b).sum(0) + 1e-8) - np.log((y_t + y_b).sum() + 1e-8))\n",
    "    ru = np.logical_and(y_b, np.logical_not(y_t)) * ic\n",
    "    mi = np.logical_and(y_t, np.logical_not(y_b)) * ic\n",
    "    return np.sqrt((alpha * ru.sum(1))**2 + ((1 - alpha) * mi.sum(1))**2).mean()\n",
    "\n",
    "f, thr = fmax(y_stack, y_pred_stack)\n",
    "print(f\"\\n STACKING (GPU-Keras MLP)\")\n",
    "print(f\"Fmax  = {f:.4f}\")\n",
    "print(f\"Thr.  = {thr:.2f}\")\n",
    "print(f\"AuPRC = {auprc(y_stack, y_pred_stack):.4f}\")\n",
    "print(f\"Smin  = {smin(y_stack, y_pred_stack, thr):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00695029-3d24-4803-a6e1-8ac5fd70b710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guardado em models/modelo_ensemble_stacking.keras\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/modelo_ensemble_stacking.keras\")\n",
    "print('guardado em models/modelo_ensemble_stacking.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37629e3a-1c24-4f0f-9d12-dddf48be8724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
